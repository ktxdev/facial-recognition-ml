{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjxx4/PDnwKIm8tR885dC+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktxdev/facial-recognition-ml/blob/master/modelling_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stakeholders\n",
        "Our stakeholder, Yeshiva University, plans to use facial recognition to automatically track student attendance. The goal is to accurately record which students attend each class.\n",
        "\n",
        "# Problem\n",
        "Yeshiva University requested that we develop a model to accurately recognize students' faces and record attendance. However, the models we tested did not perform well, with F1 scores ranging from 20% to 35%, indicating a high error rate. This report examines the challenges encountered and suggests strategies for improving the system.\n",
        "\n",
        "# Dataset\n",
        "We utilized the [Labelled Faces in the Wild dataset](https://www.kaggle.com/datasets/jessicali9530/lfw-dataset) dataset from Kaggle, which contains 13,233 images of 5,749 individuals. For our analysis, we selected 158 individuals who had 10 or more images, using exactly 10 images per person. The dataset presented challenges due to variations in facial expressions, the presence of multiple people in some images, and accessories such as hats and glasses.\n",
        "\n",
        "# Models and Why we chose them\n",
        "We tested three models: k-Nearest Neighbors (k-NN), Support Vector Machine (SVM), and XGBoost. The k-NN model was selected for its simplicity, as it makes predictions by comparing a new image with its closest neighbors. However, it can become slow when working with large numbers of images. The SVM model was chosen because it handles high-dimensional data, such as images, effectively. A limitation of SVM is that it can be computationally expensive for large datasets. XGBoost was selected for its strength in handling complex data, but it struggled with the high dimensionality of the images and did not perform as expected.\n",
        "\n",
        "# Feature Engineering & Selection\n",
        "We used SelectKBest to identify the most relevant features for classification. Each model used different numbers of top features based on perfomance. After SelectKBs=est we used PCA to reduce dimensionalit and extract key components from the selected features. Each pipeline tested different numbers of components to find the right balance between compression and information retention.\n",
        "\n",
        "# Results and Evaluation\n",
        "|Model     |Optimal Parameters       |Accuracy|Precision|Recall|f1-score|\n",
        "|----------|-------------------------|--------|---------|------|--------|\n",
        "|SVC|**SVC:**|||||\n",
        "||kernel=\"linear\"|||||\n",
        "||gamma=\"scale\"|||||\n",
        "||degree=10|||||\n",
        "||class_weight=\"balanced\"|||||\n",
        "||C=0.1|||||\n",
        "||**PCA:**|||||\n",
        "||n_components=150|||||\n",
        "||**SelectKBest:**|||||\n",
        "||k = 1500|34.18%|39.96%|34.18%|33.03%|\n",
        "|XGBoost|**XGBoost:**|||||\n",
        "||booster=\"gbtree\"|||||\n",
        "||eval_metric=\"logloss\"|||||\n",
        "||learning_rate=0.2|||||\n",
        "||max_depth=4|||||\n",
        "||n_estimators=300|||||\n",
        "||objective=\"multi:softprob\"|||||\n",
        "||**PCA:**|||||\n",
        "||n_components=100|||||\n",
        "||**SelectKBest:**|||||\n",
        "||k=2000|21.84%|26.25%|21.84%|20.8%|\n",
        "|KNeighborsClassifier|**KNeighborsClassifier:**|||||\n",
        "||n_neighbors=2|||||\n",
        "||p=1|||||\n",
        "||weights=\"distance\"|||||\n",
        "||**PCA:**|||||\n",
        "||n_components=150|||||\n",
        "||**SelectKBest:**|||||\n",
        "||k=1000|25.63%|32.45%|25.63%|25.68%|\n",
        "\n",
        "# Challenges and Limitations\n",
        "The variations in facial angles and the presence of accessories made it challenging for the models to accurately differentiate between individuals. Even with ten images per person, the sample size was insufficient for effective learning. The k-NN model performed poorly because it relies on feature similarity, which is difficult to achieve in a complex feature space. The SVM model faced issues with lengthy training times and struggled to generalize well. XGBoost was also unsuitable for high-dimensional image data, even after applying PCA for dimensionality reduction.\n",
        "\n",
        "# What Could Be Done Differently?\n",
        "1. Use convolutional nueral networks which are more suited for image data\n",
        "2. Increase the number of images per individual and adding more individuals\n",
        "\n",
        "# Conclusion\n",
        "In conclusion, these models are not yet suitable for real-world applications. With F1 scores ranging from 20% to 35%, they would produce too many errors, making them unfit for deployment in a student attendance system. For future research, we recommend exploring CNN-based models, as they are better suited for handling image data\n"
      ],
      "metadata": {
        "id": "5OkyDphAXs0y"
      }
    }
  ]
}